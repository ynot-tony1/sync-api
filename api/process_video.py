import os
import logging
from api.utils.file_utils import FileUtils
from api.utils.ffmpeg_utils import FFmpegUtils
from api.utils.syncnet_utils import SyncNetUtils
from api.utils.analysis_utils import AnalysisUtils
from api.config.settings import (
    RUN_LOGS_DIR, LOGS_DIR, FINAL_LOGS_DIR, DEFAULT_MAX_ITERATIONS,
    DEFAULT_TOLERANCE_MS, TEMP_PROCESSING_DIR, DATA_WORK_PYAVI_DIR,
    FINAL_OUTPUT_DIR
)

logger = logging.getLogger('run_postline')

def process_video(input_file, original_filename):
    """
    synchronizes a video file by processing it with the offset generated by the syncnet pipeline.
      - prepares necessary directories
      - copies the input file to a temporary folder
      - moves the file to the pipelineâ€™s data directory
      - retrieves the video's fps
      - checks for audio stream. if none is found, returns a small json dict "no_audio"
      - runs a loop (DEFAULT_MAX_ITERATIONS) of:
         1) run pipeline & syncnet -> get offset
         2) add offset to total_shift_ms
         3) if |offset| <= tolerance, break
         4) otherwise, shift the intermediate file
         5) increment reference_number
      - after the loop, applies the *cumulative* shift to the original input_file for the final output
      - verifies the final output
      - if the *very first* offset is 0, returns a dict (indicating the file was already in sync) without shifting anything

    returns:
        str or dict or None
          - str: path to the final synchronized video if any shifting was needed
          - dict: 
              * if the first offset is 0 => {"already_in_sync": True, ...}
              * if no audio => {"no_audio": True, ...}
          - None: if processing fails at any point
    """
    try:
        logger.info("starting video synchronization process...")

        # ensuring all required directories exist
        directories = [
            LOGS_DIR, RUN_LOGS_DIR, FINAL_LOGS_DIR, TEMP_PROCESSING_DIR,
            DATA_WORK_PYAVI_DIR, FINAL_OUTPUT_DIR
        ]
        FileUtils.prepare_directories(directories)

        # get the next directory reference number
        reference_number = int(FileUtils.get_next_directory_number())

        # copy input to temp, then move it into the data work directory
        temp_copy_path = FileUtils.copy_input_to_temp(input_file, original_filename)
        destination_path = FileUtils.move_to_data_work(temp_copy_path, reference_number)

        # if that final path doesn't exist, return none
        if not os.path.exists(destination_path):
            logger.error(f"destination file {destination_path} does not exist. aborting process.")
            return None

        # get the fps of the video
        fps = FFmpegUtils.get_video_fps(input_file)
        if fps is None:
            logger.error("could not retrieve fps from the video. aborting process.")
            return None

        #  check if there's an audio stream, if no audio, return a json to the front end
        audio_props = FFmpegUtils.get_audio_properties(input_file)
        if audio_props is None:
            logger.error("no audio stream found in the video. returning a JSON dict.")
            return {
                "no_audio": True,
                "message": "the video you uploaded has no audio"
            }

        total_shift_ms = 0
        
        # initialize corrected_file as the file moved to the data directory        
        corrected_file = destination_path

        # iterate through sync steps
        for iteration in range(DEFAULT_MAX_ITERATIONS):
            logger.info(f"--- synchronization iteration {iteration + 1} ---")
            # format the ref string
            ref_str = f"{reference_number:05d}"

            # run the pipeline and then syncnet
            SyncNetUtils.run_pipeline(corrected_file, ref_str)
            log_file = SyncNetUtils.run_syncnet(ref_str)

            # analyze the log to get offset
            offset_ms = AnalysisUtils.analyze_syncnet_log(log_file, fps)
            total_shift_ms += offset_ms
            logger.info(f"total shift after iteration {iteration + 1}: {total_shift_ms} ms")

            # if the offset is 0 on the 0th iteration, return a status json to the front end
            if iteration == 0 and offset_ms == 0:
                logger.info("first run offset is 0 ms; file is already synchronized, returning JSON dict.")
                return {
                    "already_in_sync": True,
                    "message": "your file was already in sync"
                }

            # if the offset is within the tolerance, break
            if abs(offset_ms) <= DEFAULT_TOLERANCE_MS:
                logger.info("synchronization offset is within the acceptable tolerance.")
                break

            # apply the offset shift for the next iteration
            new_corrected_file = os.path.join(
                TEMP_PROCESSING_DIR,
                f"corrected_iter{iteration + 1}_{original_filename}"
            )
            FFmpegUtils.shift_audio(corrected_file, new_corrected_file, offset_ms)
            if not os.path.exists(new_corrected_file):
                logger.error(f"corrected file {new_corrected_file} was not created. aborting process.")
                return None

            corrected_file = new_corrected_file
            reference_number += 1

        # apply the cumulative shift to generate the final output
        final_output_path = os.path.join(FINAL_OUTPUT_DIR, f"corrected_{original_filename}")
        FFmpegUtils.apply_cumulative_shift(input_file, final_output_path, total_shift_ms)

        # run final verification
        AnalysisUtils.verify_synchronization(
            final_output_path, f"{reference_number:05d}", fps, DEFAULT_TOLERANCE_MS
        )

        # if a correction was applied remove the last corrected_file
        if corrected_file != destination_path and os.path.exists(corrected_file):
            os.remove(corrected_file)

        return final_output_path

    except Exception as e:
        logger.error(f"an error occurred during video processing: {e}")
        return None
